{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cY8hBSvR2UCU"
   },
   "source": [
    "# **Text Classification for Topic Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBw-jy2f7xvY"
   },
   "source": [
    "# Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lk8XUaog2XRN",
    "outputId": "56626f1f-80f4-4b1d-da0e-cdabaf8a56b5"
   },
   "outputs": [],
   "source": [
    "# Install necessary dependencies\n",
    "!pip install transformers torch datasets imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uuRO-Vcewfu7"
   },
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn utilities\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Classical ML models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Resampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Hugging Face Transformers\n",
    "import torch\n",
    "from datasets import Dataset, Value\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    TextClassificationPipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GClDSOrzu0IA",
    "outputId": "54686517-a711-40fc-f581-e4ca0eb79d70"
   },
   "outputs": [],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt_tab')  # For word tokenization\n",
    "nltk.download('stopwords')  # For stopwords list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4lX23Sq2fVc"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkvUwhAh7cxF"
   },
   "source": [
    "https://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOZMrQoV2hdg",
    "outputId": "ff67a045-3408-41de-d741-0c2aa5659ffd"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive to access dataset\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-TRMz0C2jIn",
    "outputId": "c8221b9a-3ab3-4d39-b4a9-2f4f0215feaf"
   },
   "outputs": [],
   "source": [
    "# Set Path to Dataset in Google Drive\n",
    "data_dir = '/content/drive/My Drive/reuters21578'  # Update this to your folder path\n",
    "print(f\"Dataset path: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_LjY5aPvjbR"
   },
   "outputs": [],
   "source": [
    "# Helper function adapted from https://github.com/marius92mc/document-classification-reuters21578/blob/master/classification/reuters_parser.py\n",
    "\n",
    "# Define ReutersParser class (adapted from SGML parser)\n",
    "class ReutersParser(HTMLParser):\n",
    "    def __init__(self, encoding='latin-1'):\n",
    "        HTMLParser.__init__(self)\n",
    "        self._reset()\n",
    "        self.encoding = encoding\n",
    "\n",
    "    def _reset(self):\n",
    "        self.in_body = False\n",
    "        self.in_topics = False\n",
    "        self.in_topic_d = False\n",
    "        self.in_reuters = False\n",
    "        self.body = \"\"\n",
    "        self.topics = []\n",
    "        self.topic_d = \"\"\n",
    "        self.reuters = \"\"\n",
    "        self.cgisplit = \"\"\n",
    "\n",
    "    def parse(self, fd):\n",
    "        self.docs = []\n",
    "        for chunk in fd:\n",
    "            self.feed(chunk)\n",
    "            for doc in self.docs:\n",
    "                yield doc\n",
    "            self.docs = []\n",
    "        self.close()\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == \"reuters\":\n",
    "            self.in_reuters = True\n",
    "            for attribute in attrs:\n",
    "                if attribute[0] == \"cgisplit\":\n",
    "                    self.cgisplit = attribute[1].encode(\"utf-8\").lower()\n",
    "                    break\n",
    "        elif tag == \"body\":\n",
    "            self.in_body = True\n",
    "        elif tag == \"topics\":\n",
    "            self.in_topics = True\n",
    "        elif tag == \"d\":\n",
    "            self.in_topic_d = True\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        if tag == \"reuters\":\n",
    "            self.body = re.sub(r'\\s+', r' ', self.body)\n",
    "            self.in_reuters = False\n",
    "            self.docs.append((self.topics, self.body, self.cgisplit))\n",
    "            self._reset()\n",
    "        elif tag == \"body\":\n",
    "            self.in_body = False\n",
    "        elif tag == \"topics\":\n",
    "            self.in_topics = False\n",
    "        elif tag == \"d\":\n",
    "            self.in_topic_d = False\n",
    "            self.topics.append(self.topic_d)\n",
    "            self.topic_d = \"\"\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        if self.in_body:\n",
    "            self.body += data\n",
    "        elif self.in_topic_d:\n",
    "            self.topic_d += data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKIqLjWevje4"
   },
   "outputs": [],
   "source": [
    "# Parse the SGML files from Google Drive folder\n",
    "def parse_sgm(data_dir):\n",
    "    articles = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.sgm'):\n",
    "            try:\n",
    "                file_path = os.path.join(data_dir, filename)\n",
    "                print(f\"Parsing file: {file_path}\")\n",
    "\n",
    "                parser = ReutersParser(encoding='latin-1')\n",
    "                with open(file_path, 'r', encoding='latin-1') as file:\n",
    "                    for topics, body, cgisplit in parser.parse(file):\n",
    "                        articles.append({\"text\": body, \"categories\": topics})\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing file {filename}: {e}\")\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-OMuRkrvjh4",
    "outputId": "0ae7ac83-cd69-4bc6-d679-ea70e8a5bf62"
   },
   "outputs": [],
   "source": [
    "articles = parse_sgm(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiXBdFL7vjks"
   },
   "outputs": [],
   "source": [
    "# Convert to a Pandas DataFrame for easier handling\n",
    "df = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUb90zoM2rBM"
   },
   "source": [
    "# Preprocess and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9TacQo7vjne"
   },
   "outputs": [],
   "source": [
    "# Preprocess the Text Data (Tokenization, Stopwords Removal, Stemming)\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    # Tokenization and lowercasing\n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [word for word in words if word.isalpha()]  # Remove non-alphabetic characters\n",
    "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    words = [stemmer.stem(word) for word in words]  # Apply stemming\n",
    "\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buh_CkgRu0QU"
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing to all articles\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9Bnew_32xc6"
   },
   "source": [
    "### Convert Multilabel to Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMoVYCJ4x6s0"
   },
   "outputs": [],
   "source": [
    "# Ensure unique_categories is defined\n",
    "unique_categories = list(set([category for sublist in df['categories'] for category in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JrZOkRdnu0Tc"
   },
   "outputs": [],
   "source": [
    "# Convert Multi-Label to Multi-Class Based on the Most Frequent Label\n",
    "def get_most_frequent_label(categories, unique_categories):\n",
    "    if not categories:  # Check if the categories list is empty\n",
    "        return np.random.choice(unique_categories)  # Return a random label if no categories exist\n",
    "    label_counts = {label: categories.count(label) for label in set(categories)}\n",
    "    max_count = max(label_counts.values())  # Find the label(s) with the highest frequency\n",
    "    most_frequent_labels = [label for label, count in label_counts.items() if count == max_count]\n",
    "    return np.random.choice(most_frequent_labels)  # Randomly select in case of tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajybfqN3u0WD"
   },
   "outputs": [],
   "source": [
    "df['most_frequent_label'] = df['categories'].apply(lambda x: get_most_frequent_label(x, unique_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w5ZIKM-gyDaf",
    "outputId": "ec7bec70-d21c-4c05-835e-c425ba546352"
   },
   "outputs": [],
   "source": [
    "# Checking the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRIX6zkw3A0j"
   },
   "source": [
    "### Check for Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYzUsj5HsX99",
    "outputId": "0773b334-387b-4876-b00f-f1a029379616"
   },
   "outputs": [],
   "source": [
    "# Number of unique classes\n",
    "num_unique_classes = df['most_frequent_label'].nunique()\n",
    "print(f\"Number of unique classes: {num_unique_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sjVebCZyyhmS"
   },
   "outputs": [],
   "source": [
    "# Count the frequency of each label in the 'most_frequent_label' column\n",
    "label_counts = Counter(df['most_frequent_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFva_woS3Re4"
   },
   "outputs": [],
   "source": [
    "# Convert the label counts to a DataFrame for easier handling\n",
    "label_df = pd.DataFrame(label_counts.items(), columns=['Category', 'Count'])\n",
    "label_df = label_df.sort_values(by='Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "M9zYmm4k3RnO",
    "outputId": "08da1484-20da-4fdf-f8fc-382d68f7d548"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of categories\n",
    "plt.figure(figsize=(12, 6))\n",
    "label_df.head(20).plot(kind='bar', x='Category', y='Count', legend=False)\n",
    "plt.title(\"Top 20 Categories in Reuters-21578 Dataset (Converted to Single Class)\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRNRQN_J3SGT",
    "outputId": "4e20f470-c565-41c1-d90a-9e80e9c8386e"
   },
   "outputs": [],
   "source": [
    "# Print out the top 20 categories and their counts\n",
    "print(\"Top 20 categories by frequency:\\n\", label_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7UF0ulo3bc9",
    "outputId": "6144c5d7-94c1-4856-dede-68569675237c"
   },
   "outputs": [],
   "source": [
    "# Check the class distribution in percentage\n",
    "label_df['Percentage'] = label_df['Count'] / label_df['Count'].sum() * 100\n",
    "print(\"Class distribution (in percentage):\\n\", label_df[['Category', 'Percentage']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XV9B_ibE3OL-"
   },
   "source": [
    "### Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlW5zKb2wAnE"
   },
   "outputs": [],
   "source": [
    "# Convert Processed Text into TF-IDF Features\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df['processed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4o_z7Bx3KgE"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rObJYQFLqAcR"
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHxvxbumwAqY"
   },
   "outputs": [],
   "source": [
    "# Split Data into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['most_frequent_label'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TF1H2yD3qlc"
   },
   "source": [
    "## Train Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUyg4fS0wA3u"
   },
   "outputs": [],
   "source": [
    "# Initialize Naive Bayes model\n",
    "nb_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnkHmHdewUz2"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mu9BeEfjwU3i",
    "outputId": "3ae0c5fa-e920-4ce3-8a29-78c9f66cfa4b"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Naive Bayes Model without SMOTE:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eg1_XmKl4JNv"
   },
   "source": [
    "## Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqF8YA191oVj"
   },
   "outputs": [],
   "source": [
    "# Initialize Random Forest classifier with class weights\n",
    "rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "89PorNnt4t2n",
    "outputId": "3452aed1-dc3f-496c-9280-56de79c47f95"
   },
   "outputs": [],
   "source": [
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYCj4XNU4t6u"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrSalVv-4t_u",
    "outputId": "de686716-ee49-432e-961a-85a3f6a05ffd"
   },
   "outputs": [],
   "source": [
    "# Evaluate the Random Forest model\n",
    "print(\"Random Forest Model Evaluation:\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_rf)}')\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5G3aHjF6AQJ"
   },
   "source": [
    "## Random Forest: Hyperparameter Tuning with RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIauK21t6Chl"
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid for Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(50, 500, 50),  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "    'bootstrap': [True, False],  # Whether bootstrap samples are used when building trees\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWOLMR1wAMvk"
   },
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkmaC64LAM8K"
   },
   "outputs": [],
   "source": [
    "# Setup RandomizedSearchCV to search over the parameter grid\n",
    "random_search = RandomizedSearchCV(rf_model, param_distributions=param_dist,\n",
    "                                   n_iter=10, cv=3, n_jobs=-1, random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUzM_f_sANET"
   },
   "outputs": [],
   "source": [
    "# Train the model with hyperparameter tuning\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pXRyLKq-ari",
    "outputId": "0599766f-ff96-4ba1-ed0f-f63ead4aba44"
   },
   "outputs": [],
   "source": [
    "print(f\"Best parameters found: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KF6fwBRG-dqp"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using the best parameters\n",
    "y_pred_rf = random_search.predict(X_test)  # Predict using the best model found by RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhcRPi3M-e7J",
    "outputId": "edd5ceda-bf0f-4f55-edb1-f459f0d1cdaa"
   },
   "outputs": [],
   "source": [
    "# Display the classification report\n",
    "print(\"Random Forest Model Evaluation with Hyperparameter Tuning:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf)}\")\n",
    "print(classification_report(y_test, y_pred_rf))  # Shows precision, recall, f1-score for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3ojbxFQaWoW"
   },
   "source": [
    "## Train XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwa2jgdMZZLJ"
   },
   "outputs": [],
   "source": [
    "# Remove rare classes (fewer than 2 samples)\n",
    "label_counts = df['most_frequent_label'].value_counts()\n",
    "valid_labels = label_counts[label_counts >= 2].index\n",
    "df_filtered = df[df['most_frequent_label'].isin(valid_labels)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LrdZh7RaX97"
   },
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df_filtered['label_encoded'] = label_encoder.fit_transform(df_filtered['most_frequent_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQQTAgnCaYM8"
   },
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "# Split the data only AFTER filtering rare classes and re-encoding labels.\n",
    "# This ensures the label indices are consistent, and stratified split won't break due to classes with only 1 sample.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X[df_filtered.index],  # Make sure X matches filtered rows\n",
    "    df_filtered['label_encoded'],\n",
    "    test_size=0.3,\n",
    "    stratify=df_filtered['label_encoded'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LK6FFBI5sDRp",
    "outputId": "ac31639e-b25a-48fe-8f8a-4ae25e2f7ff0"
   },
   "outputs": [],
   "source": [
    "# Count unique classes in training set\n",
    "n_classes = len(np.unique(y_train_encoded))\n",
    "print(\"Number of unique classes in training set:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMTG3DO3sDZ8"
   },
   "outputs": [],
   "source": [
    "# Initialize XGBoost classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=n_classes,\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "w5fPGxSTphCL",
    "outputId": "e1bb9a9f-0b74-4a6d-eaf9-8984435ab890"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RN-x88c1j-Fv"
   },
   "outputs": [],
   "source": [
    "# Predict and evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIC3jUDTpwa3",
    "outputId": "8298217d-e8c4-4031-ca7f-1de3547d3fa5"
   },
   "outputs": [],
   "source": [
    "print(\"XGBoost Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_encoded, y_pred_xgb):.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_encoded, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DGKyYr1BAC9"
   },
   "source": [
    "## Train BERT Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzIDHOO9iSjP"
   },
   "outputs": [],
   "source": [
    "# Debugging Setup\n",
    "# Enables clearer CUDA traceback on crash\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2maabXGiSvY"
   },
   "outputs": [],
   "source": [
    "# Filter Rare Classes\n",
    "label_counts = df['most_frequent_label'].value_counts()\n",
    "valid_labels = label_counts[label_counts >= 5].index  # Only keep classes with at least 5 examples\n",
    "df_filtered = df[df['most_frequent_label'].isin(valid_labels)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dGUXLQhiS-2",
    "outputId": "b1d5918b-e41a-4308-a51a-769bd58e8b1f"
   },
   "outputs": [],
   "source": [
    "# Encode Labels\n",
    "label_encoder = LabelEncoder()\n",
    "df_filtered['label'] = label_encoder.fit_transform(df_filtered['most_frequent_label'])\n",
    "num_labels = df_filtered['label'].nunique()\n",
    "\n",
    "print(\"Min label:\", df_filtered['label'].min())\n",
    "print(\"Max label:\", df_filtered['label'].max())\n",
    "print(\"Number of labels:\", num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_ClsNzKiZYz",
    "outputId": "39bf44e4-fc70-413f-f79c-341be4a6e4aa"
   },
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df_filtered['processed_text'].tolist(),\n",
    "    df_filtered['label'].tolist(),\n",
    "    test_size=0.3,\n",
    "    stratify=df_filtered['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train labels range:\", min(train_labels), max(train_labels))\n",
    "print(\"Test labels range:\", min(test_labels), max(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "e5e2f344cce349ec9b73906c4d38314b",
      "f22ec3f460aa47638e4ddb67658a9565",
      "bec4acaf3d6b4923bdc7ec3220526975",
      "337f9248498c40109cbfacf599317de0",
      "ea44202c6c5f4ff4ac993840cf547c58",
      "2f03c82ce4354338b08bd67d8c872f00",
      "82c4003141e6455ea6c30fe4cf99e468",
      "0f143e04036b476a81eaeb431db658a7",
      "172b2e04f84b447dbd01dc4e6eb98fd3",
      "8811003ae9564ad888ead6e82eeb377f",
      "2524ba2147b2498b89438086e4ab11f0",
      "a56cf8bfc0e7490c906eb60d7a1d396d",
      "d8f96fb16e614602bf57f81a4f6ec705",
      "0d8c2f7f5e164bb1a1b0d3f39f0dc781",
      "cbe1aaff4d7447178563ec457ec3b022",
      "00cd70f4570c48a892c192aac312206d",
      "1de878f8615b4d9582c20408773f1c8d",
      "3d3d723a986347a7b9091fe216b39029",
      "4d7d1a8427324203b96ef5ef47791a2c",
      "30961b527fe0491d98a8c91953d56f09",
      "bc41ca1f2c8a4cf98fbcfbd97d16ae5a",
      "a0a38e0ea49c4a0fae8bfc2a9057f740"
     ]
    },
    "id": "ybCeCqcdicpP",
    "outputId": "6686e696-d7b3-44c2-d7cf-3c7f22de99cf"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels}).map(tokenize, batched=True)\n",
    "test_dataset = Dataset.from_dict({\"text\": test_texts, \"label\": test_labels}).map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRA-8hcCigNh"
   },
   "outputs": [],
   "source": [
    "# Compute Metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\", zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556,
     "referenced_widgets": [
      "89e12110ab0e4eca963e4b3faf1a40b8",
      "6a47984bc19145c19829735c195b7f5d",
      "05c9299e002744efb7c7d169d03fa726",
      "0cf4fda37f5e43b7892452f422133bbd",
      "b2eb3af7b87845a592f5846b9347c226",
      "79f92f6ed6d5438087806691b84d638f",
      "165032b062144c8d9cfe4be1b6c070a7",
      "c9a9f0ba81f7433a92797468e96f5913",
      "b9df82672bfd4310b7709fc770307474",
      "6b4f24bef6854755a14f321e10c2757a",
      "a98fdaa57d8348f8b832eb1bb42bed56",
      "e62bc0c3043f40cabad36917f5d3cf3c",
      "9049177fe40b479fa44248605f047d3d",
      "139409fbf3b44953b86b7c29c7ffc430",
      "4b81c61817c64d1e963ba36117d67eca",
      "cc93b3fbcce84677a70e3f2875a6c791",
      "eff01a50024a4bb9b067bb2575d8a5b2",
      "3dabd53ee9ac4864ab335521ef3453cc",
      "eb40bceb823b41cb861086ee0eac5303",
      "701dc9e05e444a71945331c7fbea7201",
      "24ba2669d17a43969149cf2c69debbe9",
      "f617e05425db4e98bb9ca4bfcb06ef14",
      "78edc28703204fcea10507f49bcf70b5",
      "4ba87351d1ba407ebc536081f7080fab",
      "5cfb587253d3493dbbbbf836d9788001",
      "64595a01c37f4bd4ad79b3551361cb6d",
      "6782c6e5cf9244da94cbccb1507ff067",
      "9f4a26c48785407fa2d97c7850650862",
      "ab8dac5413534f0e9bca016a9cdc77b3",
      "5a534428603440e685b83845ac2343bb",
      "ef004c8ae65344479b890e97e15f4b9f",
      "96dbcb29fc1e4b0f855470710e57359a",
      "54bdafd1f52d428ba5a19f15a5bba892",
      "67288b4ec1f843fcb50f91674c30a946",
      "56932228f1914e14891464631413e0e8",
      "4518324fc1d14563b41d65616625f2ea",
      "04e41402bb834157879a909d9bef2b71",
      "d5f125887cf948d09a12fcc7d525d50d",
      "8dd16962586c4f8c9aeb52ab364ed32c",
      "2d73cd6a4c384db58e36f87c45e43ca8",
      "1d91bf131d83436db7fff60187ca7119",
      "253f522ab65d4c398915c71f06943fd9",
      "85000418a1fa4153908e9a9aa81fbf0b",
      "87de5c43d9ed4ae1a70bb177f74692e0",
      "00922fb66bda46f68d6b8e24940fcb12",
      "9b6d651034504b40add0e2a6484e3a7f",
      "5fca0a1f09354da9bc3712d715aa0aa8",
      "e42fa88c20d54a07a9823f09ac5723d4",
      "538d8b1b36b646139f34e9ffce555f28",
      "57eed36bbd524655b4c8686e00640246",
      "f274baba6f31427090b61abddb1cc69e",
      "e7f38096fd2c41419f6eff92432d5d05",
      "ad9f3f5660194db8b4706ed5fad3bfdd",
      "211e3a16e5044defb8c613983e551716",
      "0450b318fab3474c95b83bf7b5ecafb3",
      "9901001b545c4f9297bf399231b99c8e",
      "55055b11d263453aaf3d4d4ca9d81193",
      "52e82f1eb8a641a295c25f17a29b45c6",
      "b5533344a4e4424facc71f2301d544ce",
      "866dbbb15f1f48768930fa7b6b8354fd",
      "7755782096a547e3a00501ccd272b1fe",
      "cd5d75425ec74697b78eed4b9dc2a1c5",
      "0d3a8611c1ac4a8e92e464a46053b05b",
      "81078b2d0ce94d4296f8a899ae83f8f6",
      "b89a9f705c6c4cceb19702aa5a35b2df",
      "64945f31167d4e54b55d0d20e45dd510",
      "19f9a8f2a3034e0fb20b70928e88353c",
      "e4891395a87f41b5858ca5edc426e9cf",
      "39accaff911e40f2900f1000df8242d4",
      "339dc4e5bc5d4fc997b1293f6188403d",
      "6ec359f4e7104bd79431e32d63b87b4a",
      "ea45e672362a4808be412f0f45ed13e9",
      "8008cfda0d714a2998351b08a2372296",
      "84b788cc5a1944438357ae0105696c50",
      "a0f807f55157456f8b9b262ca9ca2ab7",
      "b2c621d0bcf743c9b44b56a03731afb6",
      "2395b281f0f9439ebb2a37c88787b079"
     ]
    },
    "id": "71nc7wjE8pLh",
    "outputId": "3ec309bf-0374-4a73-b9ae-4a0c587c3e84"
   },
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,     # Smaller batch size to avoid CUDA issues\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "3uKyxrDoBZb9",
    "outputId": "fab73000-d196-4a05-923c-c905e1d9935e"
   },
   "outputs": [],
   "source": [
    "# Trainer Setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "72l9Q7QR8pTD",
    "outputId": "7f5b0132-c302-4872-c99c-05fee26533cb"
   },
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "metrics = trainer.evaluate()\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbEvynutfe3R"
   },
   "source": [
    "##  Save & Load BERT Model to/from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nr1VI81pfhRi",
    "outputId": "1e169d7c-8786-4feb-da28-dcb19a3955ef"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feWkOWTMfk2n"
   },
   "outputs": [],
   "source": [
    "# Define Save Path\n",
    "save_path = \"/content/drive/MyDrive/reuters_classifier\"\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JfkOHe3Kfngv",
    "outputId": "96a9807e-13a4-402b-93dd-2440c91e08ce"
   },
   "outputs": [],
   "source": [
    "# Save the trained BERT model and tokenizer for future use\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5mRx34ufvyk"
   },
   "source": [
    "### Load the Saved Model for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqlGLzxDfnpa"
   },
   "outputs": [],
   "source": [
    "# Load Model and Tokenizer from Google Drive without retraining\n",
    "load_path = \"/content/drive/MyDrive/reuters_classifier\"\n",
    "model = DistilBertForSequenceClassification.from_pretrained(load_path)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(load_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuAIbFKrgaou"
   },
   "outputs": [],
   "source": [
    "def create_classification_pipeline(model, tokenizer, use_gpu=True, return_probs=False):\n",
    "    \"\"\"\n",
    "    Create a text classification pipeline with the given model and tokenizer.\n",
    "    \"\"\"\n",
    "    # Make sure model is in evaluation mode and on the correct device\n",
    "    device = 0 if (use_gpu and torch.cuda.is_available()) else -1\n",
    "    return TextClassificationPipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device=device,\n",
    "        return_all_scores=return_probs\n",
    "    )\n",
    "\n",
    "def extract_predicted_class_ids(predictions):\n",
    "    \"\"\"\n",
    "    Extract class IDs from pipeline predictions.\n",
    "    \"\"\"\n",
    "    return [int(pred['label'].split('_')[-1]) for pred in predictions]\n",
    "\n",
    "def decode_predictions(class_ids, label_encoder):\n",
    "    \"\"\"\n",
    "    Decode integer class IDs into original label names.\n",
    "    \"\"\"\n",
    "    return label_encoder.inverse_transform(class_ids)\n",
    "\n",
    "def predict_texts(texts, model, tokenizer, label_encoder, use_gpu=True, return_probs=False):\n",
    "    \"\"\"\n",
    "    Complete modular prediction pipeline:\n",
    "    - Create pipeline\n",
    "    - Predict\n",
    "    - Decode labels\n",
    "    \"\"\"\n",
    "    pipeline = create_classification_pipeline(model, tokenizer, use_gpu, return_probs)\n",
    "    predictions = pipeline(texts)\n",
    "\n",
    "    if return_probs:\n",
    "        return predictions  # Raw scores for all classes\n",
    "\n",
    "    class_ids = extract_predicted_class_ids(predictions)\n",
    "    decoded_labels = decode_predictions(class_ids, label_encoder)\n",
    "    return decoded_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uVcajULx6F7"
   },
   "source": [
    "# Model Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXEXwylpuoyO"
   },
   "source": [
    "# Predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFqS1SDMuDYG",
    "outputId": "f5f0d8be-80e4-48ca-9bc6-b0416888db66"
   },
   "outputs": [],
   "source": [
    "#generated example texts\n",
    "unseen_texts = [\n",
    "    \"The stock market responded positively to the company's earnings report.\",\n",
    "    \"The agricultural sector saw a sharp drop in wheat exports.\",\n",
    "    \"Major oil producers are discussing supply cuts.\"\n",
    "]\n",
    "\n",
    "predicted = predict_texts(unseen_texts, model, tokenizer, label_encoder)\n",
    "\n",
    "for text, label in zip(unseen_texts, predicted):\n",
    "    print(f\"Text:\\n{text}\\n→ Predicted Label: {label}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4Zu-Of1j_6x"
   },
   "source": [
    "### Predict on Twitter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ND717rpTjkQj"
   },
   "outputs": [],
   "source": [
    "def load_and_clean_tweet_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and clean the tweet dataset.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with columns ['id', 'tweet', 'labels'].\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, header=None, usecols=[0, 1, 2], names=[\"id\", \"tweet\", \"labels\"], encoding=\"utf-8\", engine='python', on_bad_lines='skip')\n",
    "\n",
    "    # Drop rows with missing or empty labels\n",
    "    df = df[df['labels'].notna() & (df['labels'].str.strip() != \"\")]\n",
    "\n",
    "    # Remove stray semicolons and clean whitespace\n",
    "    df['labels'] = df['labels'].astype(str).str.replace(\";\", \"\", regex=False).str.strip()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "_fjF8bFIjrVi",
    "outputId": "7965d49e-01be-4fc0-8873-668556aa1f1e"
   },
   "outputs": [],
   "source": [
    "twitter_df = load_and_clean_tweet_data(\"/content/drive/MyDrive/mLabel_tweets.csv\")\n",
    "twitter_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZA9aaznyj0LH"
   },
   "outputs": [],
   "source": [
    "# Sample 10 random tweets from the dataset\n",
    "sampled_tweets = df.sample(n=10, random_state=42)['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bd_k1w70kxWO"
   },
   "outputs": [],
   "source": [
    "# Format into a list of strings\n",
    "unseen_texts = [str(tweet) for tweet in sampled_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2VCd4gRkxrY"
   },
   "outputs": [],
   "source": [
    "# Print the result\n",
    "print(\"unseen_texts = [\")\n",
    "for tweet in unseen_texts:\n",
    "    print(f'    \"{tweet}\",')\n",
    "print(\"]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9MhkgqR5pTf",
    "outputId": "fbc09be8-19ff-4682-f3ea-790af6d76206"
   },
   "outputs": [],
   "source": [
    "# Make predictions on Twitter dataset\n",
    "predicted = predict_texts(unseen_texts, model, tokenizer, label_encoder)\n",
    "\n",
    "for text, label in zip(unseen_texts, predicted):\n",
    "    print(f\"Text:\\n{text}\\n→ Predicted Label: {label}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3u8hT3Obiek"
   },
   "source": [
    "## Finetuning on Twitter Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4C3_OHc64kY"
   },
   "source": [
    "https://www.kaggle.com/datasets/prox37/twitter-multilabel-classification-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZexMSTlQbsgZ"
   },
   "outputs": [],
   "source": [
    "# Set Device & Seed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KXmBlHXjt3Bc",
    "outputId": "ffe81179-4c6e-4bdf-aab5-e80096588d76"
   },
   "outputs": [],
   "source": [
    "# Load and Clean Data\n",
    "def load_twitter_data(path):\n",
    "    df = pd.read_csv(path, header=None, names=[\"id\", \"tweet\", \"labels\"], usecols=[0, 1, 2],\n",
    "                     encoding=\"utf-8\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "    df = df[df[\"labels\"].notna() & (df[\"labels\"].str.strip() != \"\")]\n",
    "    df[\"labels\"] = df[\"labels\"].astype(str).str.replace(\";\", \"\", regex=False).str.strip()\n",
    "    return df\n",
    "\n",
    "df = load_twitter_data(\"/content/drive/MyDrive/mLabel_tweets.csv\")\n",
    "\n",
    "# Encode labels first\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label_raw\"] = df[\"labels\"]\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"label_raw\"])\n",
    "\n",
    "# Remove classes that appear only once\n",
    "label_counts = df[\"label\"].value_counts()\n",
    "valid_labels = label_counts[label_counts > 1].index\n",
    "df = df[df[\"label\"].isin(valid_labels)].copy()\n",
    "\n",
    "# Re-encode after filtering\n",
    "df[\"label_raw\"] = label_encoder.inverse_transform(df[\"label\"])\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"label_raw\"])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "print(\"Number of unique classes after filtering:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uc0GzbImt3Hr"
   },
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"tweet\"].tolist(),\n",
    "    df[\"label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnzCZgpQt3Nj"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# Create HuggingFace Datasets\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"text\": train_texts,\n",
    "    \"label\": [int(label) for label in train_labels]\n",
    "}).map(tokenize, batched=True)\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"text\": test_texts,\n",
    "    \"label\": [int(label) for label in test_labels]\n",
    "}).map(tokenize, batched=True)\n",
    "\n",
    "# Fix label dtype for CrossEntropyLoss\n",
    "train_dataset = train_dataset.cast_column(\"label\", Value(\"int64\"))\n",
    "test_dataset = test_dataset.cast_column(\"label\", Value(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4F7sMm6sEsU"
   },
   "outputs": [],
   "source": [
    "# Load and Adapt Pretrained Base Model\n",
    "from transformers import DistilBertConfig\n",
    "\n",
    "# Load config and change num_labels\n",
    "config = DistilBertConfig.from_pretrained(load_path)\n",
    "config.num_labels = num_classes\n",
    "\n",
    "# Load the model WITHOUT classification head weights\n",
    "model = DistilBertForSequenceClassification.from_pretrained(load_path, config=config, ignore_mismatched_sizes=True)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfF9owyAsE3A"
   },
   "outputs": [],
   "source": [
    "#  Metrics\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred.predictions, pred.label_ids\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds, average=\"weighted\", zero_division=0),\n",
    "        \"recall\": recall_score(labels, preds, average=\"weighted\", zero_division=0),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\", zero_division=0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661,
     "referenced_widgets": [
      "8583135fdafc4a39af39f0cef9de5505",
      "8b19cfa5e6f34e22bd2831ddda5c4ac0",
      "ef87c535345842448124190a0c121544",
      "a6d80f67b842451f8db48b7643e673d3",
      "9b5b91c93bf04da39a843389db8f3a91",
      "862b670128c24384ba11a40a25e73819",
      "01990858f5714cea871537836b825e80",
      "4ca856591a9345638f406bee85363221",
      "7b3daf0e36034986946a37ebf981f979",
      "fd870ae0a1ee4f6f8e2c1235023cca1f",
      "c84e83711ed5407b881d124ffd926047",
      "31f1e9f2c4c14710b2ee649239275ac7",
      "250bfaaada2e487aa16165d11ffe17fb",
      "a683217efdf1411f9b0c953e33905eed",
      "6a9113a051974cc688bb0a9ab378df04",
      "363c429926524f5e9adf594a5248de05",
      "97c1b7e8cacb446ca16514535fa94d30",
      "df9758eedad143899c7fb5cb9b4a4430",
      "9271a329033f427d80b1e0f263f63eac",
      "79d12edf68c7443392a85845a5b6b6c4",
      "39f976e7e98245f19791e14b7d5a59a4",
      "1490db6f6d864f769cb76b22437aa48a",
      "ce3216b167e24c36a3e2b3605530a8d5",
      "42a09c2ce7404dffa31f0ce2078ccfbb",
      "fbb5b3328d3848d0b9491b64d9875978",
      "8a3318974a50481480d9384a6d5f3492",
      "d1ef1dc449e34d2fb54f74e6e80dce67",
      "7521401bc99d4b1c8f9b48a239d802d5",
      "c935d23182c2417ca64ee5fc205b453a",
      "9083c9e505e4480e8a5bcc8e69ecbb60",
      "2e6f19d77de541b6aa00a07d8dd0ac58",
      "40c6849f0cd84838b769c7df50b04184",
      "8b39384106d647299d55306001f91062",
      "5a6ab676537144d58a5192fd6952d4cb",
      "dd02e95c0904447994571ea5f967963e",
      "4136eb41aaaa4d158057741e799798b4",
      "c63dd307d41e4695854d1c0e46a6df8c",
      "ea1818a8286f417e9a329fe32d8865ac",
      "60abe40d52bc4330ae44925e4546fb13",
      "f25aa4c47b1d4a89bbdc3080d7ada1a6",
      "c1287c78f7fc4ac2bdf4df2fe5d35bd5",
      "9e66ef32388f4b28a73808e0d787b4d4",
      "d7a2aa88cdec4997a0bd0a471a33c63f",
      "dacf54ab377848e18050ec60923cc1c7"
     ]
    },
    "id": "vfe8H1s6bsrr",
    "outputId": "dfd5d209-27d9-4205-9d27-424101148b2d"
   },
   "outputs": [],
   "source": [
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_twitter_finetune\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_dir=\"./logs_twitter_finetune\",\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "Hrmjgj-JrJbj",
    "outputId": "f4f66d1b-5ef7-4c3d-b7f4-93f5b2eac3be"
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "metrics = trainer.evaluate()\n",
    "print(\"Final Evaluation on Twitter Data:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcbMk0Xftksh",
    "outputId": "df0444d7-e23f-4388-8c4b-95cf7ab0be48"
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "save_path = \"/content/drive/MyDrive/twitter_finetuned_bert\"\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZgjyh7ysXbu"
   },
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ft8ALMDetHJ4",
    "outputId": "2921c95c-f3b3-4f81-b033-b320d093129e"
   },
   "outputs": [],
   "source": [
    "#generated example texts\n",
    "unseen_texts = [\n",
    "    \"Vaccines have many side effects including blood clots.\",\n",
    "    \"I don't trust pharmaceutical companies making money off this.\",\n",
    "    \"It is a rushed and untested experiment.\",\n",
    "    \"Vaccines are unnecessary because we have natural immunity.\"\n",
    "]\n",
    "\n",
    "predicted = predict_texts(unseen_texts, model, tokenizer, label_encoder)\n",
    "\n",
    "for text, label in zip(unseen_texts, predicted):\n",
    "    print(f\"Text:\\n{text}\\n→ Predicted Label: {label}\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
